# Personalized Recommendation System

A comprehensive recommendation system that implements multiple recommendation algorithms including collaborative filtering, content-based filtering, and neural networks. This project demonstrates key ML engineering skills used in companies like Google, Microsoft, Amazon, Netflix, and others.

## Project Overview

This recommendation system includes:

1. **Data Pipeline**: Collects, processes, and stores user interactions and item metadata
2. **Multiple Recommendation Algorithms**:
   - Memory-based collaborative filtering (user-based, item-based)
   - Model-based collaborative filtering (matrix factorization)
   - Content-based recommender
   - Neural network-based recommender
   - Hybrid approach combining multiple algorithms
3. **Evaluation Framework**: Metrics and utilities to compare different algorithms
4. **RESTful API**: FastAPI backend to serve recommendations
5. **Web Interface**: Flask frontend to interact with recommendations

## Repository Structure

```
recommendation-system/
├── data/
│   ├── raw/                  # Raw data files
│   ├── processed/            # Processed data files
│   └── data_pipeline.py      # Data processing utilities
├── models/
│   ├── collaborative_filtering.py  # Collaborative filtering models
│   ├── content_based.py      # Content-based recommendation model
│   └── neural_network.py     # Neural network recommendation model
├── api.py                    # FastAPI application
├── evaluation.py             # Evaluation metrics and utilities
├── frontend/
│   ├── app.py                # Flask application
│   └── templates/            # HTML templates
├── Dockerfile.api            # Dockerfile for API
├── Dockerfile.frontend       # Dockerfile for frontend
├── docker-compose.yml        # Docker Compose configuration
├── requirements.api.txt      # Dependencies for API
└── requirements.frontend.txt # Dependencies for frontend
```

## Prerequisites

- Python 3.9+
- Docker and Docker Compose (for containerized deployment)
- 4+ GB RAM (especially for neural network model training)

## Setup and Installation

### Option 1: Local Development

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/recommendation-system.git
   cd recommendation-system
   ```

2. Create a virtual environment:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.api.txt
   pip install -r requirements.frontend.txt
   ```

4. Download the MovieLens dataset (automatically handled by the data pipeline on first run)

5. Run the data pipeline to prepare the data:
   ```bash
   python -c "from data.data_pipeline import DataPipeline; pipeline = DataPipeline(); pipeline.process_pipeline()"
   ```

6. Start the API (in one terminal):
   ```bash
   uvicorn api:app --reload --host 0.0.0.0 --port 8000
   ```

7. Start the frontend (in another terminal):
   ```bash
   cd frontend
   flask run --host 0.0.0.0 --port 5000
   ```

8. Access the web interface at http://localhost:5000

### Option 2: Docker Deployment

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/recommendation-system.git
   cd recommendation-system
   ```

2. Build and start the containers:
   ```bash
   docker-compose up -d
   ```

3. Access the web interface at http://localhost:5000

## Usage

1. **Register/Login**: Use any numeric ID to create a profile or log in
2. **Update Preferences**: Set genre preferences to improve initial recommendations
3. **Rate Movies**: Rate movies to train the recommendation system
4. **View Recommendations**: Explore recommendations generated by different algorithms
5. **Compare Algorithms**: Try different recommendation approaches to see which works best for you

## API Documentation

The API documentation is available at http://localhost:8000/docs when the API is running.

Key endpoints:
- `POST /recommendations`: Get personalized recommendations
- `POST /rate`: Rate a movie
- `GET /profile/{user_id}`: Get user profile
- `POST /profile`: Update user profile
- `GET /movies/{movie_id}`: Get movie details
- `GET /similar/{movie_id}`: Get similar movies

## Model Training

The models are automatically trained when the API starts for the first time. You can retrain models with:

```python
from models.collaborative_filtering import MemoryBasedCF, MatrixFactorizationCF
from models.content_based import ContentBasedRecommender
from models.neural_network import NeuralRecommender
from data.data_pipeline import DataPipeline
import scipy.sparse as sp

# Load data
pipeline = DataPipeline()
train_matrix = sp.load_npz("data/processed/interaction_matrix.npz")
movies_df = pd.read_csv("data/processed/processed_movies.csv")

# Train collaborative filtering model
cf_model = MemoryBasedCF(method='item')
cf_model.fit(train_matrix)
cf_model.save_model("models/collaborative_filtering/item_based_cf.pkl")

# Train content-based model
content_model = ContentBasedRecommender()
content_model.fit(movies_df)
content_model.save_model("models/content_based/content_recommender.pkl")
```

## Extending the System

### Adding a New Algorithm

1. Create a new model file in the `models/` directory
2. Implement the model with `fit()`, `predict()`, and `recommend()` methods
3. Update the API's `get_recommendations()` function to include your new algorithm
4. Add the algorithm to the frontend's options

### Using a Different Dataset

1. Modify the `DataPipeline` class to handle your dataset format
2. Update the preprocessing steps as needed
3. Ensure your dataset has user-item interactions and item metadata

## Evaluation

The system includes an evaluation framework in `evaluation.py` for comparing different algorithms:

```python
from evaluation import RecommenderEvaluator
import pandas as pd

# Load test data
test_df = pd.read_csv("data/processed/test_ratings.csv")
train_df = pd.read_csv("data/processed/train_ratings.csv")

# Create evaluator
evaluator = RecommenderEvaluator()

# Evaluate rating prediction
evaluator.evaluate_rating_prediction(cf_model, test_df, name="Item-Based CF")
evaluator.evaluate_rating_prediction(matrix_model, test_df, name="Matrix Factorization")

# Evaluate top-N recommendations
evaluator.evaluate_top_n_recommendations(
    cf_model, test_df, train_df, n=10, name="Item-Based CF"
)

# Compare results
results = evaluator.compare_models()
print(results)
```

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

- MovieLens dataset by GroupLens Research
- Inspired by recommendation systems at companies like Netflix, Amazon, and Spotify
